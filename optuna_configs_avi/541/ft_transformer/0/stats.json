{
    "config": {
        "base_config": {
            "data": {
                "cat_policy": "indices",
                "dset_id": 541,
                "normalization": "quantile",
                "task": "regression",
                "y_policy": "mean_std"
            },
            "model": {
                "activation": "reglu",
                "initialization": "kaiming",
                "n_heads": 8,
                "prenormalization": true
            },
            "seed": 0,
            "training": {
                "batch_size": 256,
                "eval_batch_size": 8192,
                "lr_n_decays": 0,
                "n_epochs": 500,
                "num_batch_warm_up": 0,
                "optimizer": "adamw",
                "patience": 30
            },
            "transfer": {
                "checkpoint_path": NaN,
                "downstream_samples_per_class": NaN,
                "epochs_warm_up_head": 0,
                "freeze_feature_extractor": false,
                "head_lr": NaN,
                "layers_to_fine_tune": [],
                "load_checkpoint": false,
                "pretrain_proportion": 0.5,
                "stage": "pretrain",
                "use_mlp_head": false
            }
        },
        "optimization": {
            "options": {
                "n_trials": 30
            },
            "sampler": {
                "seed": 0
            },
            "space": {
                "model": {
                    "attention_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "d_ffn_factor": [
                        "$d_ffn_factor",
                        1.0,
                        4.0
                    ],
                    "d_token": [
                        "$d_token",
                        64,
                        512
                    ],
                    "ffn_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "n_layers": [
                        "int",
                        1,
                        4
                    ],
                    "residual_dropout": [
                        "?uniform",
                        0.0,
                        0.0,
                        0.2
                    ]
                },
                "training": {
                    "lr": [
                        "loguniform",
                        1e-05,
                        0.001
                    ],
                    "weight_decay": [
                        "loguniform",
                        1e-06,
                        0.001
                    ]
                }
            }
        },
        "program": "bin/ft_transformer.py"
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.2",
            "torch.backends.cudnn.version()": 7605,
            "torch.cuda.nccl.version()": 2708,
            "driver": "470.57.02",
            "0": {
                "name": "NVIDIA GeForce RTX 2080 Ti",
                "total_memory": 11554717696
            }
        }
    },
    "best_stats": {
        "dataset": 541,
        "algorithm": "ft_transformer",
        "config": {
            "data": {
                "cat_policy": "indices",
                "dset_id": 541,
                "normalization": "quantile",
                "task": "regression",
                "y_policy": "mean_std"
            },
            "model": {
                "activation": "reglu",
                "attention_dropout": 0.0145522011297429,
                "d_ffn_factor": 0.9384489267447308,
                "d_token": 288,
                "ffn_dropout": 0.04510346984923107,
                "initialization": "kaiming",
                "n_heads": 8,
                "n_layers": 2,
                "prenormalization": true,
                "residual_dropout": 0.0
            },
            "seed": 0,
            "training": {
                "batch_size": 256,
                "eval_batch_size": 8192,
                "lr": 9.200592579617476e-05,
                "lr_n_decays": 0,
                "n_epochs": 500,
                "num_batch_warm_up": 0,
                "optimizer": "adamw",
                "patience": 30,
                "weight_decay": 2.259125904388358e-06
            },
            "transfer": {
                "checkpoint_path": NaN,
                "downstream_samples_per_class": NaN,
                "epochs_warm_up_head": 0,
                "freeze_feature_extractor": false,
                "head_lr": NaN,
                "layers_to_fine_tune": [],
                "load_checkpoint": false,
                "pretrain_proportion": 0.5,
                "stage": "pretrain",
                "use_mlp_head": false
            }
        },
        "environment": {
            "devices": {
                "CUDA_VISIBLE_DEVICES": "0",
                "torch.version.cuda": "10.2",
                "torch.backends.cudnn.version()": 7605,
                "torch.cuda.nccl.version()": 2708,
                "driver": "470.57.02",
                "0": {
                    "name": "NVIDIA GeForce RTX 2080 Ti",
                    "total_memory": 11554717696
                }
            }
        },
        "replacement_sampling": false,
        "num_classes_train": NaN,
        "num_classes_test": NaN,
        "num_training_samples": 378,
        "cat_features_no": 4,
        "num_features_no": 1,
        "epoch_size": 2,
        "n_parameters": 1149625,
        "best_epoch": 15,
        "metrics": {
            "train": {
                "rmse": 0.5778010452918191,
                "score": -0.5778010452918191
            },
            "val": {
                "rmse": 0.7536431203531387,
                "score": -0.7536431203531387
            },
            "test": {
                "rmse": 0.750965083008493,
                "score": -0.750965083008493
            }
        },
        "time": "0:00:02",
        "trial_id": 22,
        "tuning_time": "0:03:32"
    },
    "time": "0:04:29"
}
