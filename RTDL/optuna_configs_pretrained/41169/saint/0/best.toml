seed = 0

[data]
cat_policy = 'indices'
dset_id = 41169
normalization = 'quantile'
task = 'multiclass'

[model]
attentiontype = 'colrow'
attn_dropout = 0.6530407001627145
cont_embeddings = 'MLP'
depth = 1
embed_dim = 34
ff_dropout = 0.4002197646675801
final_mlp_style = 'sep'
heads = 4
use_cls = true

[training]
batch_size = 506
lr = 2.324374290939867e-05
lr_n_decays = 0
n_epochs = 500
num_batch_warm_up = 0
optimizer = 'adamw'
patience = 30
weight_decay = 0.0009410144991942522

[transfer]
checkpoint_path = nan
downstream_samples_per_class = nan
epochs_warm_up_head = 0
freeze_feature_extractor = false
head_lr = nan
layers_to_fine_tune = []
load_checkpoint = false
pretrain_proportion = 0.5
stage = 'pretrain'
use_mlp_head = false
