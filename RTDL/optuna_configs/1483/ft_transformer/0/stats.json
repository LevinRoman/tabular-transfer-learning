{
    "config": {
        "base_config": {
            "data": {
                "cat_policy": "indices",
                "dset_id": 1483,
                "normalization": "quantile",
                "task": "multiclass"
            },
            "model": {
                "activation": "reglu",
                "initialization": "kaiming",
                "n_heads": 8,
                "prenormalization": true
            },
            "seed": 0,
            "training": {
                "batch_size": 256,
                "eval_batch_size": 8192,
                "lr_n_decays": 0,
                "n_epochs": 500,
                "num_batch_warm_up": 0,
                "optimizer": "adamw",
                "patience": 30
            },
            "transfer": {
                "checkpoint_path": NaN,
                "downstream_samples_per_class": NaN,
                "epochs_warm_up_head": 0,
                "freeze_feature_extractor": false,
                "head_lr": NaN,
                "layers_to_fine_tune": [],
                "load_checkpoint": false,
                "pretrain_proportion": 0.5,
                "stage": "pretrain",
                "use_mlp_head": false
            }
        },
        "optimization": {
            "options": {
                "n_trials": 100
            },
            "sampler": {
                "seed": 0
            },
            "space": {
                "model": {
                    "attention_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "d_ffn_factor": [
                        "$d_ffn_factor",
                        1.0,
                        4.0
                    ],
                    "d_token": [
                        "$d_token",
                        64,
                        512
                    ],
                    "ffn_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "n_layers": [
                        "int",
                        1,
                        4
                    ],
                    "residual_dropout": [
                        "?uniform",
                        0.0,
                        0.0,
                        0.2
                    ]
                },
                "training": {
                    "lr": [
                        "loguniform",
                        1e-05,
                        0.001
                    ],
                    "weight_decay": [
                        "loguniform",
                        1e-06,
                        0.001
                    ]
                }
            }
        },
        "program": "bin/ft_transformer.py"
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "470.57.02",
            "0": {
                "name": "NVIDIA GeForce RTX 2080 Ti",
                "total_memory": 11554717696
            }
        }
    }
}
