{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 0
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9062379483224065,
                "recall": 0.9506447534766119,
                "f1-score": 0.9279103630395616,
                "support": 19775
            },
            "1": {
                "precision": 0.8159879336349924,
                "recall": 0.6899410170572294,
                "f1-score": 0.7476893841236936,
                "support": 6273
            },
            "accuracy": 0.8878608722358723,
            "macro avg": {
                "precision": 0.8611129409786995,
                "recall": 0.8202928852669207,
                "f1-score": 0.8377998735816277,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8845035217969862,
                "recall": 0.8878608722358723,
                "f1-score": 0.8845087122126559,
                "support": 26048
            },
            "roc_auc": 0.9464683048555778,
            "score": 0.8878608722358723
        },
        "val": {
            "0": {
                "precision": 0.8966442953020134,
                "recall": 0.9456016177957532,
                "f1-score": 0.9204724409448819,
                "support": 4945
            },
            "1": {
                "precision": 0.7927580893682589,
                "recall": 0.65625,
                "f1-score": 0.7180739706908583,
                "support": 1568
            },
            "accuracy": 0.8759404268386304,
            "macro avg": {
                "precision": 0.8447011923351362,
                "recall": 0.8009258088978766,
                "f1-score": 0.8192732058178701,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8716337669887742,
                "recall": 0.8759404268386304,
                "f1-score": 0.8717451568425775,
                "support": 6513
            },
            "roc_auc": 0.927482795443759,
            "score": 0.8759404268386304
        },
        "test": {
            "0": {
                "precision": 0.895678776290631,
                "recall": 0.9417772416566144,
                "f1-score": 0.9181497451979614,
                "support": 12435
            },
            "1": {
                "precision": 0.7741734248284466,
                "recall": 0.6453458138325533,
                "f1-score": 0.7039137833238797,
                "support": 3846
            },
            "accuracy": 0.8717523493642897,
            "macro avg": {
                "precision": 0.8349261005595388,
                "recall": 0.7935615277445838,
                "f1-score": 0.8110317642609206,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8669760195973344,
                "recall": 0.8717523493642897,
                "f1-score": 0.8675415817333266,
                "support": 16281
            },
            "roc_auc": 0.9274991578674006,
            "score": 0.8717523493642897
        }
    },
    "time": "0:00:02"
}
