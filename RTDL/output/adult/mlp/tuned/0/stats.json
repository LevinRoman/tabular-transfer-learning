{
    "dataset": "adult",
    "algorithm": "mlp",
    "config": {
        "data": {
            "cat_policy": "indices",
            "normalization": "quantile",
            "path": "data/adult"
        },
        "model": {
            "d_embedding": 421,
            "d_layers": [
                42,
                503,
                503,
                503,
                111
            ],
            "dropout": 0.0
        },
        "seed": 0,
        "training": {
            "batch_size": 256,
            "eval_batch_size": 8192,
            "lr": 0.0003214782880724119,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 7.16873819458233e-05
        }
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "epoch_size": 102,
    "n_parameters": 769401,
    "best_epoch": 20,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9089696071163825,
                "recall": 0.9301137800252844,
                "f1-score": 0.919420144963759,
                "support": 19775
            },
            "1": {
                "precision": 0.7622570101496645,
                "recall": 0.7063605930176949,
                "f1-score": 0.7332450769485355,
                "support": 6273
            },
            "accuracy": 0.8762285012285013,
            "macro avg": {
                "precision": 0.8356133086330235,
                "recall": 0.8182371865214897,
                "f1-score": 0.8263326109561473,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8736376000228543,
                "recall": 0.8762285012285013,
                "f1-score": 0.8745846028238827,
                "support": 26048
            },
            "roc_auc": 0.9349917562535482,
            "pr_auc": 0.8371665397835574,
            "score": 0.8762285012285013
        },
        "val": {
            "0": {
                "precision": 0.8918387413962635,
                "recall": 0.917087967644085,
                "f1-score": 0.9042871385842473,
                "support": 4945
            },
            "1": {
                "precision": 0.7128851540616247,
                "recall": 0.6492346938775511,
                "f1-score": 0.6795727636849134,
                "support": 1568
            },
            "accuracy": 0.8526024873330262,
            "macro avg": {
                "precision": 0.8023619477289441,
                "recall": 0.7831613307608181,
                "f1-score": 0.7919299511345803,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.848755795758199,
                "recall": 0.8526024873330262,
                "f1-score": 0.8501873167138103,
                "support": 6513
            },
            "roc_auc": 0.9055339602979715,
            "pr_auc": 0.7649686694847936,
            "score": 0.8526024873330262
        },
        "test": {
            "0": {
                "precision": 0.8939632133312372,
                "recall": 0.9145958986731001,
                "f1-score": 0.9041618634972374,
                "support": 12435
            },
            "1": {
                "precision": 0.7016015734756954,
                "recall": 0.6492459698387936,
                "f1-score": 0.67440918298447,
                "support": 3846
            },
            "accuracy": 0.8519132731404705,
            "macro avg": {
                "precision": 0.7977823934034662,
                "recall": 0.7819209342559468,
                "f1-score": 0.7892855232408537,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8485223394976635,
                "recall": 0.8519132731404705,
                "f1-score": 0.849888243372423,
                "support": 16281
            },
            "roc_auc": 0.9059138408962173,
            "pr_auc": 0.7664430704219508,
            "score": 0.8519132731404705
        }
    },
    "time": "0:00:27"
}
